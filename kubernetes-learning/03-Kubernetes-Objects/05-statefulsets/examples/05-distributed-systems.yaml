# StatefulSet Examples for Distributed Systems
# This file demonstrates StatefulSet configurations for popular distributed applications

# Example 1: Elasticsearch Cluster
# A distributed search and analytics engine
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  clusterIP: None                    # Headless service for internal discovery
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    name: rest                       # REST API
  - port: 9300
    name: inter-node                 # Inter-node communication
---
# Client-facing service
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-client
  labels:
    app: elasticsearch
    role: client
spec:
  selector:
    app: elasticsearch
    role: client
  ports:
  - port: 9200
    name: rest
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: es-cluster
spec:
  serviceName: elasticsearch
  replicas: 3
  podManagementPolicy: Parallel      # Create pods in parallel for faster startup
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0                   # Update all pods when changed
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      affinity:                      # Ensure pods are on different nodes
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - elasticsearch
            topologyKey: "kubernetes.io/hostname"
      initContainers:
      - name: fix-permissions
        image: busybox:1.28
        command: ["sh", "-c", "chown -R 1000:1000 /usr/share/elasticsearch/data"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
      - name: increase-vm-max-map
        image: busybox:1.28
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
      - name: increase-fd-ulimit
        image: busybox:1.28
        command: ["sh", "-c", "ulimit -n 65536"]
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
        env:
        - name: cluster.name
          value: k8s-elasticsearch
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: "es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "es-cluster-0,es-cluster-1,es-cluster-2"
        - name: ES_JAVA_OPTS
          value: "-Xms512m -Xmx512m"
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 512Mi
        ports:
        - containerPort: 9200
          name: rest
        - containerPort: 9300
          name: inter-node
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 20
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 10
      terminationGracePeriodSeconds: 120  # Give ES time to gracefully leave the cluster
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 20Gi

---
# Example 2: Kafka Cluster
# A distributed streaming platform
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    name: kafka
  clusterIP: None                    # Headless service for internal discovery
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    name: kafka
  selector:
    app: kafka                       # Standard service for external access
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:6.2.0
        ports:
        - containerPort: 9092
          name: kafka
        env:
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper:2181"           # Requires separate ZooKeeper deployment
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://$(POD_NAME).kafka-headless:9092"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name      # Extract ordinal from pod name
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"                        # Replicate offset topic for durability
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"                        # Default replication factor for topics
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"                        # Require at least 2 replicas to be in-sync
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        readinessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 9092
          initialDelaySeconds: 60
          periodSeconds: 20
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 20Gi

---
# Example 3: Redis Cluster with Sentinel
# A distributed in-memory database with high-availability
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
data:
  redis.conf: |
    dir /data
    appendonly yes
    protected-mode no
    maxmemory 512mb
    maxmemory-policy volatile-lru
  sentinel.conf: |
    dir /data
    sentinel monitor mymaster redis-0.redis-headless 6379 2
    sentinel down-after-milliseconds mymaster 5000
    sentinel failover-timeout mymaster 60000
    sentinel parallel-syncs mymaster 1
---
apiVersion: v1
kind: Service
metadata:
  name: redis-headless
spec:
  clusterIP: None
  selector:
    app: redis
  ports:
  - port: 6379
    name: redis
  - port: 26379
    name: sentinel
---
apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    name: redis
    targetPort: 6379
---
apiVersion: v1
kind: Service
metadata:
  name: redis-sentinel
spec:
  selector:
    app: redis
  ports:
  - port: 26379
    name: sentinel
    targetPort: 26379
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
spec:
  serviceName: redis-headless
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      initContainers:
      - name: init-redis
        image: redis:6.2-alpine
        command:
        - sh
        - -c
        - |
          set -ex
          # Extract ordinal from hostname
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          
          # Configure redis.conf for role
          if [ $ordinal = 0 ]; then
            echo "This is the master node"
            # No special config for master
          else
            echo "This is a replica node, will connect to redis-0"
            echo "replicaof redis-0.redis-headless 6379" >> /etc/redis/redis.conf
          fi
          
          # Copy final config to data directory
          cp /etc/redis/redis.conf /data/redis.conf
          cp /etc/redis/sentinel.conf /data/sentinel.conf
        volumeMounts:
        - name: redis-config
          mountPath: /etc/redis/
        - name: data
          mountPath: /data
      containers:
      - name: redis
        image: redis:6.2-alpine
        command: ["redis-server", "/data/redis.conf"]
        ports:
        - containerPort: 6379
          name: redis
        volumeMounts:
        - name: data
          mountPath: /data
        livenessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - redis-cli ping
          initialDelaySeconds: 5
          periodSeconds: 10
      - name: sentinel
        image: redis:6.2-alpine
        command: ["redis-sentinel", "/data/sentinel.conf"]
        ports:
        - containerPort: 26379
          name: sentinel
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi 